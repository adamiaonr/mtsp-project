\section{Discussion}
\label{sec:discussion}

Figures~\ref{fig:exp-results-topologies-cascade} and~\ref{fig:exp-results-topologies-tree} 
show a comparison of the quantity of Interest and Data packets received\slash sent 
per topology level, for both the cascade and binary tree topologies in 
Figure~\ref{fig:exp-setup-nettop}. Both topologies clearly show a significantly 
larger number of received Interest signals at level 2 (in fact, level 2 receives 
all the Interest signals generated by the clients at level 1), compared to 
a much smaller number of Interest signals relayed to the subsequent `upstream' 
levels. This is a result of two features of NDN: (1) the aggregation of Interest 
signals in PITs; and (2) cache hits in the CSs. Also note the 
difference in nearly one order of magnitude of the 
Interests forwarded `upstream' for both topologies, e.g. at level 2, $\sim2 \times 10^4$ Interest signals 
are forwarded for the cascade case, vs. $\sim1.5 \times 10^5$ in the binary 
tree topology case. This is obviously a consequence of the larger number of 
clients contained in the binary tree topology. The quantity of Interests forwarded 
`upstream' is generally larger in the case for the MRU cache algorithm, due to 
the smaller contribution of cache hits (e.g. as seen in 
Figure~\ref{fig:exp-results-cache-alg-cascade}). The differences between cache 
algorithms are accentuated in Data packet statistics: e.g. focusing on 
Figure~\ref{fig:exp-results-topologies-cascade}, while for LRU the quantity of 
Data packets sent by level 2 is practically equal to the number of received 
Interests, the same does not happen with MRU, with a difference of 
$4 \times 10^4$ to $\sim2.5 \times 10^4$. This is mostly due to the fact that 
MRU does not favor the most popular content, whose Interests have to be forwarded 
much further `upstream' to be satisfied, resulting in larger accumulations of 
pending Interests at lower levels. Another interesting phenomena is 
verified in Figure~\ref{fig:exp-results-topologies-tree-lru}, specifically 
regarding the binary tree topology: note how the quantity of Data packets 
received at level 1 far exceeds the generated Interest signals. This happens 
due to the sharing of the interfaces $F_{r,1}$ of the routers at level 1 per each pair of 
clients, and subsequent duplication of Data signals. Again, the difference is 
not exactly a 2:1 ratio due to the action of Interest signal aggregation at 
PITs.\shortvertbreak

Figures~\ref{fig:exp-results-cache-alg-cascade} and~\ref{fig:exp-results-cache-alg-tree} 
show the cache hit\slash miss rates for the different topologies and all considered 
caching algorithms. We can not a similarity in the trends of the LRU and Random caching 
algorithms, favoring the most popular content, nevertheless with LRU favoring it 
in a larger degree. For both topology types, level 2 (the first level after the 
`layer' of clients) exhibits significantly larger cache hit rate values for the most 
popular content than for the subsequent `upstream' levels. This indicates 
that CSs at level 2 become mostly occupied by popular content objects, hence explaining 
some of the results previously analyzed in Figures~\ref{fig:exp-results-topologies-cascade} 
and~\ref{fig:exp-results-topologies-tree}. Regarding topologies, 
the differences between Figures~\ref{fig:exp-results-cache-alg-cascade-lru} 
and~\ref{fig:exp-results-cache-alg-tree-lru} seem to indicate a larger `caching 
capacity' for the binary tree topology, as it presents overall larger hit rate 
values across all content objects. This is not surprising, due to the 
larger number of routers (and hence cache capacity) per level. Note, however, 
that such differences are 
only verified with the LRU algorithm, being mitigated with Random caching. The 
MRU algorithm does the opposite, 
favoring the less popular content and `flattening' the overall hit rates (at lower 
values). In fact, these results somehow show the unsuitability of the MRU cache 
algorithm for the model of Interest signal generation we consider here, i.e. with 
independent inter-arrival times. The MRU algorithm is mostly indicated for 
situations in which the inter-arrival times of events are not independent between 
each other, e.g. in cases where the occurrence of some event $e$ at some point 
in time indicates that the same event is unlikely to occur in the near future. On the 
other hand, the LRU algorithm, designed to favor events which are likely to be occur 
in `bursts' and concentrated in specific time periods, favors popular content (whose Interest 
generation occurs more often and therefore exhibiting smaller intervals between occurrences), 
despite our usage of independent inter-arrival times.\shortvertbreak

Figures~\ref{fig:exp-results-latency-cascade} and~\ref{fig:exp-results-latency-tree} show 
the ratio of received Interests to original requests, per content object 
and network level (including server(s) $S$), for both topology types considered in the 
experiments. These charts is provide an idea of the `latency' a client can expect for 
the satisfaction of an Interest for some content object, in the sense that it shows how far (i.e. to 
which level) are Interests forwarded `upstream'. Overall, and for both topologies, 
the following aspects can be highlighted: 

\begin{itemize}
    \item All original Interest requests are 
        received by level 2 (the first layer of routers after the clients), as expected;
    \item For the LRU and Random cache algorithms, the ratio is greatly reduced for 
        the most popular content objects, with values $\sim0$ for the LRU algorithm, 
        indicating that these content instances are mostly cached and served at 
        lower levels of the topologies, and therefore accessed with lower latencies;
    \item For both LRU and Random algorithms, the ratio values increase with the index of 
        content objects, i.e. with the reduction of their popularity, indicating that 
        Interests for less popular content tend to cross more topology levels and 
        are therefore accessed with larger latencies (e.g. in the case of $O_{100}$ 
        the ratio value of level 5 --- of the server $S$ --- is contained in the 
        interval $[0.5, 0.8]$, meaning 
        that more that $50\%$ of the Interest signals for $O_{100}$ need to actually 
        reach $S$ to be satisfied);
    \item The ratio values for a given content object tend to decrease with the topology 
        levels, both as a result of (1) aggregation of pending Interests at PITs and 
        (2) cache hits.
\end{itemize}\shortvertbreak

One can note a difference between Figures~\ref{fig:exp-results-latency-cascade-lru} 
and~\ref{fig:exp-results-latency-tree-lru}, both pertaining to the LRU cache 
algorithm, but under different topologies: in the former, the differences in 
ratio values between levels are absent, while in the latter, a clear difference 
can be identified. The same pattern is evident in 
Figures~\ref{fig:exp-results-topologies-cascade-lru} and~\ref{fig:exp-results-topologies-tree-lru}. 
This behavior can be explained by the larger `caching capacity' of the binary 
tree topology.\shortvertbreak

The results for the MRU cache algorithm show a trend for benefiting less 
popular content, as previously identified in Figures~\ref{fig:exp-results-cache-alg-cascade-mru} 
and~\ref{fig:exp-results-cache-alg-tree-mru}. The ratio values for the 
most popular content ($O_1$ to $O_2$) are low due to the number of Interests aggregated 
at PITs at level 2, and not to a high cache hit rate, as previously verified 
in Figures~\ref{fig:exp-results-cache-alg-cascade-mru} 
and~\ref{fig:exp-results-cache-alg-tree-mru}. As MRU favors the caching of less popular 
content, the ratio values decrease with the index of content objects. Also note how the 
results for the cascade topology are more `unstable' that those of the binary 
tree case: this is due to difference in nearly one order of magnitude of the 
Interests forwarded `upstream', e.g. at level 2, $\sim2 \times 10^4$ Interest signals 
are forwarded for the cascade case, vs. $\sim1.5 \times 10^5$ in the binary 
tree topology case.\shortvertbreak

Finally, in Figures~\ref{fig:exp-results-time-cascade} 
and~\ref{fig:exp-results-time-tree}, we present the results for our last 
metric, the relative time spent at CSs, per content object and topology level. 
Here the differences between cache algorithms are much more evident than those 
between topologies. In the case of LRU, Figures~\ref{fig:exp-results-time-cascade-lru} 
and~\ref{fig:exp-results-time-tree-lru}, one can verify that content objects $O_1$ 
to $O_{10}$ are located in caches for $> 50\%$ of the simulation rounds in 
level 2, and nearly absent in levels 3 and 4. This seems to accentuate the 
idea that the exchanges of popular content are concentrated between levels 1 and 2. 
Objects $O_o$ with $o > 10$ spend more time cached at the subsequent 
levels, with relative times in the interval $[0.4, 0.1]$. Note how the binary tree's 
larger `caching capacity' rises the relative caching time of objects 
$O_o$ with $o > 10$, as well as a reduction for $1 \le o \le 10$ in levels 3 
and 4. The results for the Random cache algorithm, Figures~\ref{fig:exp-results-time-cascade-random} 
and~\ref{fig:exp-results-time-tree-random}, follow a similar 
trend to that of LRU, nevertheless with larger relative caching times for content 
objects $O_1$ to $O_{10}$ on levels 3 and 4, and a subsequent reduction for 
level 2. Regarding the MRU caching policy, the benefit of less popular content 
is also verified in Figures~\ref{fig:exp-results-time-cascade-mru} 
and~\ref{fig:exp-results-time-tree-mru}, as one notes the increase in relative 
caching time for larger content indexes, without major differences between levels. 
Furthermore, the results for the binary tree topology seem more `stable', once again 
probably due to the due to difference in nearly one order of magnitude of the 
Interests forwarded `upstream'.

